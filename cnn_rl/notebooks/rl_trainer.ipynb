{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10961,"status":"ok","timestamp":1690951165049,"user":{"displayName":"Nagaraju Oruganti","userId":"06429387525646784172"},"user_tz":-330},"id":"_LieUBBuKmUY"},"outputs":[],"source":["%%capture\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Developer/trading/cnn_rl/src\n","#%cd /content/drive/MyDrive/trading/cnn_rl/src\n","   \n","%pip install pyts"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oszD62W5KuZe","outputId":"ed2436ee-3d73-476d-b1df-fbeec140e7b5"},"outputs":[],"source":["from helper_config import Config\n","from helper_env import PortfolioEnvironment\n","from helper_agent import DQLAgent\n","from helper_dataset import RLDataset\n","cfg = Config()\n","cfg.data_dir = '../data'\n","cfg.models_dir = '../models/rl'\n","cfg.base_model_path = '../models/1dcnn_gadf_zero_centered_ohlc/baseline/model.pth'\n","target_assets = len(cfg.tickers)\n","\n","### RL / POLICY NETWORK CONFIGURATION\n","cfg.input_dim       = len(cfg.tickers) * (4)\n","cfg.output_dim      = len(cfg.tickers)  # values between 0-1 for each asset, potraying funds to be invested\n","cfg.learning_rate   = 1e-3\n","cfg.gamma           = 0.99\n","cfg.epsilon         = 1.0\n","cfg.epsilon_decay   = 0.9995\n","cfg.epsilon_min     = 0.01\n","cfg.reply_capacity  = 10000\n","cfg.batch_size      = 32\n","cfg.hidden_size     = 128\n","cfg.riskfree_rate   = 0.02\n","cfg.initial_balance = 1_000_000\n","\n","prep = RLDataset(cfg)  # we create dataset for the RL model\n","df_norm_close, df_prices, images, labels = prep.prepare(kind = 'train') # here we import the data\n","\n","# define environment\n","env = PortfolioEnvironment(cfg, df_norm_close, df_prices, images, labels, window_size = 2000) # this class defines the trading env, norm_close + logits from CNN goes to Policy Network\n","\n","# define agent\n","agent = DQLAgent(cfg, name = 'baseline')\n","results = agent.train(env, episodes = 20000) # "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yG5bIeQSPhLm"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
